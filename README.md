## General information
In this repository, we provide the artifacts of the paper "Data Scientists: Revealing their Challenges and Practices on Machine Learning Model Development".


## Data Scientists: Revealing their Challenges and Practices on Machine Learning Model Development

### Abstract
Data scientists often develop machine learning models to solve a variety of problems in the industry and academy. To build these models, these professionals usually perform activities that are also performed in the software development lifecycle, such as eliciting requirements and building models from these requirements. One might argue that data scientists could rely on the engineering of traditional software development to build machine learning models. However, machine learning development presents certain specificities, which may raise challenges that lead to the need for adopting new practices. The literature fails in characterizing this knowledge from the perspective of data scientists. In this paper, we characterize challenges and practices that emerge when engineering machine learning models and deserve attention from the research community. To this end, we perform a qualitative study with eight data scientists across five different companies with long-term experience in developing machine learning models. Our findings suggest that: (i) data processing and feature engineering are the most challenging stages in the development of machine learning models; (ii) it is essential synergy between data scientists and domain experts in most of these stages; and (iii) charts, data transformation and feature selection are the most common methods to deal with the most challenging stages. 

## Data Scientists Background

![Background](https://github.com/sbes2020/MLPractices/blob/master/background.png)

The target population of this study is composed of data scientists experienced in developing ML models. These models may be supervised or not. We recruited eight data scientists from five different companies and with years of experience in ML (see Table). The participantsâ€™ experience with ML ranges from 2 to 40 years. Besides, we selected participants working in three different domains within our industrial collaboration network: three data scientists (ğ‘‘1, ğ‘‘2, ğ‘‘4) from the oil and gas domain; three data scientists (ğ‘‘6, ğ‘‘7, ğ‘‘8) of natural resources; and two (ğ‘‘3, ğ‘‘5) data scientists working for the government. Seven data scientists declared expertise in supervised learning and two data scientists have expertise in unsupervised learning. Notice that there is one data scientist (ğ‘‘8) who has expertise in both supervised and unsupervised learning. The frameworks most frequently employed by the study subjects for developing ML models are TensorFlow, Keras, Scikit-learn, and PyTorch.

## Saturation
We defined our saturation point through some factors. We observed the data collection, examining whether our codings converged to those previously existing (see the codes available in this repository). However, we did not only rely on data to define our saturation point, other four important factors to reach an ideal number of interviews were also considered: 
1) the answers depth to meet our research goal 
2) the homogeneity of the categories emerging from the interviews
3) the number of data required to answer our research questions
4) the availability (1-hour interviews) and access (industry partnership) to interviewees

We measured the quality of these factors by answering eight questions:

1) Did all available interviews cover our research questions?
2) Did all interviewees provide clear and unambiguous answers to our research questions?
3) Does the coding emerging from these interviews answer the research objective?
4) To what extent the coding (i.e., categories) emerging from these interviews are homogeneous?
5) Can the researcher identify heterogeneity in the coding?
6) Does the coding emerging from these interviews confirm or deny the answers to our research questions?
7) Does our coding reveal data scientist's additional challenges?
8) Are there instigating findings emerging from the data?

Source and references: https://researchdesignreview.com/2012/09/12/designing-a-quality-in-depth-interview-study/

**Important:** notice that we provide one file for each data scientist (Table 1), each file in two formats: .csv for further research propose and .pdf for visualization propose. **Both files has the same content**.


